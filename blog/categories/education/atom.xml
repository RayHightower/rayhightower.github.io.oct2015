<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Education | RayHightower.com]]></title>
  <link href="http://RayHightower.com/blog/categories/education/atom.xml" rel="self"/>
  <link href="http://RayHightower.com/"/>
  <updated>2014-04-01T01:14:40-05:00</updated>
  <id>http://RayHightower.com/</id>
  <author>
    <name><![CDATA[Raymond T. Hightower - Chicago Ruby on Rails & iOS Developer]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Flourish Open Source Conference at UIC]]></title>
    <link href="http://RayHightower.com/blog/2014/03/31/flourish-open-source-conference-at-uic/"/>
    <updated>2014-03-31T23:42:00-05:00</updated>
    <id>http://RayHightower.com/blog/2014/03/31/flourish-open-source-conference-at-uic</id>
    <content type="html"><![CDATA[<p><a href="http://flourishconf.com">Flourish</a> is an open source conference to be held at the University of Illinois at Chicago on Saturday, April 5, 2014. The conference is run by university students and tickets are free.</p>

<p>Why go to Flourish? Because&hellip;</p>

<!--more-->


<ul>
<li>You like open source.</li>
<li>You want to know more about open source.</li>
<li>You want to meet people who are passionate about open source.</li>
<li>All (or some combination) of the above.</li>
</ul>


<h3>Not Just Software</h3>

<p>Linux may be the best known open source project, but open source is not just about software. At Flourish 2009 a speaker mentioned a funny little circuit board called ‚ÄúArduino‚Äù during one of the presentations. I turned to my neighbor in the audience, and I asked ‚ÄúWhat‚Äôs an Arduino?‚Äù</p>

<p>My neighbor pulled an Arduino out of his backpack and showed it to me. Wow. Open source extends to hardware, too! Since then, the Arduino has become part of the <a href="http://www.windycityrails.org/youth/">WindyCityRails Youth Program</a>. Beyond microcontrollers, <a href="/blog/2012/12/03/ruby-on-raspberry-pi/">Raspeberry Pi</a>, <a href="/blog/2014/01/02/beaglebone-black-ubuntu-part-1/">Beaglebone Black</a>, and <a href="/blog/2013/06/22/preparing-for-parallella-64-cores-installing-go-on-mac-os-x/">Parallella</a> have joined the open source hardware ranks.</p>

<h3>See You There</h3>

<p>Thank you, Flourish organizers, for inviting me to speak this year. UIC is where I first learned about open source, Linux, and the web. My appreciation for UIC extends beyond my CS degree.</p>

<p>Great things happen when like-minded people come together to exchange ideas. I look forward to seeing you at Flourish 2014!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How .gitignore Works]]></title>
    <link href="http://RayHightower.com/blog/2014/03/25/how-gitignore-works/"/>
    <updated>2014-03-25T18:20:00-05:00</updated>
    <id>http://RayHightower.com/blog/2014/03/25/how-gitignore-works</id>
    <content type="html"><![CDATA[<p>Earlier today I ran into a Git issue within a RubyMotion project. I added a directory to the project&rsquo;s <code>.gitignore</code> file, but Git seemed to ignore my ignore. Expressed more clearly, Git continued to track a directory that I explicitly told it to ignore.</p>

<p>What?</p>

<p>Either there was a bug in Git, or my understanding of <code>.gitignore</code> was incomplete. It was time for me to dig in and learn more about <code>.gitignore</code>.</p>

<!--more-->


<h3>What I Learned About .gitignore</h3>

<p>The root cause of my problem: Once Git has begun tracking a file or directory, adding it to <code>.gitignore</code> changes nothing. Git will continue to track the file unless we explicitly tell Git to stop tracking the file.</p>

<p>```bash
$ git rm &mdash;cached [filename]</p>

<p>$
```</p>

<p>Or, if you want to stop tracking an entire directory (like me in this case)&hellip;</p>

<p>```bash
$ git rm -r &mdash;cached [directoryname]</p>

<p>$
```</p>

<p>The <code>-r</code> flag will tell Git to stop tracking all of the sub-directories and files within <code>directoryname</code>, recursively.</p>

<p>Git was behaving exactly as designed.</p>

<h3>Penalty</h3>

<p>I should have known this a long time ago. My penalty: A public admission :&ndash;)</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Fixing MacVim on OS X Mavericks]]></title>
    <link href="http://RayHightower.com/blog/2014/03/04/fixing-macvim-on-osx-mavericks/"/>
    <updated>2014-03-04T14:48:00-06:00</updated>
    <id>http://RayHightower.com/blog/2014/03/04/fixing-macvim-on-osx-mavericks</id>
    <content type="html"><![CDATA[<p>Experience told me to delay upgrading to OS X Mavericks for as long as possible because the upgrade would likely break my dev environment. Sure enough, the upgrade broke <a href="/blog/2013/01/12/why-i-use-vim/">MacVim</a>.</p>

<p>```bash
~$ which mvim</p>

<p>~$
```</p>

<p>The &lsquo;nix <code>which</code> command returned a null response when asked about MacVim. Not cool, Mavericks!</p>

<!--more-->


<p>Fortunately, I‚Äôm running <a href="/blog/2014/02/12/homebrew-fundamentals/">Homebrew</a>. After the standard <code>brew doctor</code> and <code>brew update</code>, the following resolved the MacVim problem:</p>

<p>```bash
~$ brew uninstall macvim
Uninstalling /usr/local/Cellar/macvim/7.4-70&hellip;</p>

<p>~$
```</p>

<p>followed by‚Ä¶</p>

<p>```bash
~$ brew install macvim
==> Downloading <a href="https://github.com/b4winckler/macvim/archive/snapshot-72.tar.gz">https://github.com/b4winckler/macvim/archive/snapshot-72.tar.gz</a></p>

<h6>################################################################## 100.0%</h6>

<p>==> ./configure &mdash;with-features=huge &mdash;enable-multibyte &mdash;with-macarchs=x86_64 &mdash;enable-perlinterp &mdash;enable-rubyinterp &mdash;enable-tcli
==> make
==> Caveats
.app bundles were installed.
Run <code>brew linkapps</code> to symlink these to /Applications.
==> Summary
üç∫  /usr/local/Cellar/macvim/7.4-72: 1799 files, 28M, built in 37 seconds</p>

<p>~$
```</p>

<p>And now‚Ä¶</p>

<p>```bash
~$ which mvim
/usr/local/bin/mvim</p>

<p>~$
```</p>

<p>Whew. Homebrew saves the day again!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[What Is Open Source?]]></title>
    <link href="http://RayHightower.com/blog/2014/02/22/what-is-open-source/"/>
    <updated>2014-02-22T16:41:00-06:00</updated>
    <id>http://RayHightower.com/blog/2014/02/22/what-is-open-source</id>
    <content type="html"><![CDATA[<p><span class='caption-wrapper right'><img class='caption' src='/images/linux-penguin.png' width='' height='' alt='The Linux penguin.' title='The Linux penguin.'><span class='caption-text'>The Linux penguin.</span></span>
Entrepreneurs, especially those outside of software development, may find this article useful.</p>

<h3>When Performance Matters</h3>

<p>Over seventy percent of the web servers on the planet run Linux, the open source operating system. Google, Facebook, and Amazon all run Linux. They bet their companies on this decision every day.</p>

<p>Given that thousands of successful companies have bet their livelihood on open source, an observer might ask these questions:</p>

<ul>
<li>What is open source?</li>
<li>Why should one care about open source?</li>
<li>How can a company profit from software that is given away for free?</li>
</ul>


<!--more-->


<h3>Source Code, Executable Code</h3>

<p>First, a few definitions. Source code is a human-modifiable form of software. It‚Äôs software as written by programmers. Source code must be translated into executable code (either compiled or interpreted) before a computer can run it.</p>

<p>Water is a useful metaphor for this discussion. Water can exist in three different states (steam, liquid, and ice) without changing its chemical properties. It‚Äôs still water. Likewise, software can exist as source code or executable code ‚Äì it‚Äôs still software. We use water in one of its three states depending on whether we want to wash a car (liquid), cool a drink (ice), or clean a carpet (steam).</p>

<p>In the world of software, executable code is difficult for humans to read, but easily executed by computers. Source code is easily read and modified by humans, but computers cannot execute it. Source code must be compiled or interpreted before a computer can execute it.</p>

<h3>One Way Translation</h3>

<p>Translating source code into executable code is a one-way street. Once a programmer has compiled source code into executable code, it is virtually impossible to convert it back into source code. You might think of a compiler as a blender that chops the food into a form easily digestible by the computer. After it‚Äôs chopped, the food never returns to its original form.</p>

<p>That‚Äôs why programmers always keep a copy of the source code handy. It might be necessary to make changes (fix bugs) and re-compile.</p>

<p>Trade secrets that are hidden in executable code can be easily read in source code. So developers go to great lengths to protect their source code, except in the open source community.</p>

<h3>Closed Source Tradition</h3>

<p>Most of today‚Äôs business software is closed source. Two examples: Microsoft Office and Apple iWork. Both Microsoft and Apple consider the source code for their respective office suites to be highly confidential. You will never (legally) download the source code for a closed source product. Security is so tight at Microsoft, for example, that engineers are only allowed to view that portion of the source code that is relevant to their current project.</p>

<p>Contrast that against open source software. Open source products make the source code freely available for viewing, comments, and modification by the software community at large.</p>

<h3>Open Source Chaos?</h3>

<p>But doesn&rsquo;t such openness lead to chaos? Intuitively, you would think so, but it doesn&rsquo;t. The culture of the open source community has its own rules of conduct that most members willingly follow. Rules are enforced by the community in ways that developers respond to.</p>

<p>It is difficult to imagine an apparently chaotic system that produces robust software. How counter-intuitive! But a long list of successful open source projects (available through your favorite search engine) shows that the method works. Eric S. Raymond explores open source cultural norms in his book <a href="http://www.amazon.com/Cathedral-Bazaar-Musings-Accidental-Revolutionary-ebook/dp/B0026OR3LM">The Cathedral and the Bazaar</a>.</p>

<h3>The Banking Metaphor</h3>

<p>Some makers of security software believe that hiding their source code will prevent malcontents from finding vulnerabilities and exploiting them. Their reasoning is like that of a bank owner who keeps the building blueprints secret so thieves don‚Äôt know how to drill the safe from next door.</p>

<p>Other security experts disagree. They want many people (including malcontents) to view the code so that vulnerabilities can be discovered and patched early. Their philosophy could be summed up in a statement by the creator of Linux:</p>

<blockquote><p>Given enough eyeballs, all bugs are shallow.
<br/>&nbsp;
~Linus Torvalds</p></blockquote>

<p>In other words, when thousands of developers are working on the same project they are likely to be widely dispersed across the code. Wide coverage means that a given bug is more likely to be discovered by at least one developer.</p>

<p>In our banking metaphor, the open source company would be like a bank owner who wants many people to review the blueprints, find the weak spots, and fix security holes before the bank gets robbed.</p>

<h3>It‚Äôs Not All-or-Nothing</h3>

<p>Choosing an open or closed source strategy is not an all-or-nothing decision. Google, the busiest search engine on the web, has bet the company on open source software. And yet their most strategic software, the secret mathematical engine that drives their search results, remains closed. So how does a company decide what to open and what to close?</p>

<p>Open source works when the upside of sharing outweighs the downside of exposed code. In the Google example, using and contributing to Linux gives Google a very stable operating platform at a relatively low cost. In effect they are leveraging the time and talent of thousands of developers around the world, while those developers are also leveraging Google‚Äôs expertise.</p>

<p>It doesn&rsquo;t matter that Google&rsquo;s competitors also benefit from that same stable Linux platform because Google differentiates itself through advanced search technology. By leveraging the community for assistance with the platform (Linux, Apache, and other tools), Google frees up engineering time and talent to focus on their secret sauce: Search methodology and mathematics.</p>

<h3>If Your Business Isn‚Äôt Software</h3>

<p>So&hellip; If you don&rsquo;t run a software company, how can you benefit from open source?</p>

<p>There‚Äôs always a chance that open source won‚Äôt work for your company. Maybe you run an enterprise that doesn‚Äôt benefit from the web. In that case, your current software options may suit you just fine.</p>

<p>Of course, you may have already benefited from open source. There is at least a 70% chance that your company‚Äôs web site runs on Linux. If that‚Äôs the case, then rest assured that you‚Äôre running on a very stable and robust platform.</p>

<h3>Think Big, Start Small for ROI</h3>

<p>If you really want to see ROI from open source, encourage your technical team (software developers, network support, etc.) to explore open source tools. Chances are that they‚Äôve already experimented with open source and they‚Äôre waiting for an opportunity to do an official company project.</p>

<p>Start small, perhaps with an automated network monitoring project or a small database. As you explore the technology, new ideas will become apparent to you. View this as a way to accelerate and strengthen the software development process.</p>

<h3>Open Source and Automobiles</h3>

<p>BMW is arguably the best automotive engineering company on the planet. Does BMW invent the wheel every time they design a new automobile? Absolutely not. BMW leverages thousands of years of &ldquo;open source&rdquo; wheel technology, and they focus their design energy in areas where they can make a difference: Engine, transmission, suspension, and luxury amenities. A similar model can be applied to software development. In fact, it already has.</p>

<h3>Suggested Reading</h3>

<p><a href="http://www.amazon.com/Cathedral-Bazaar-Musings-Accidental-Revolutionary-ebook/dp/B0026OR3LM">The Cathedral and the Bazaar</a>, by Eric S. Raymond. The author is both participant and anthropologist in the open source community.</p>

<p><em>Note: An earlier version of this article was published at <a href="http://wisdomgroup.com">WisdomGroup.com</a></em>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[High Performance Computing at ACM]]></title>
    <link href="http://RayHightower.com/blog/2013/12/12/high-performance-computing-at-acm/"/>
    <updated>2013-12-12T22:22:00-06:00</updated>
    <id>http://RayHightower.com/blog/2013/12/12/high-performance-computing-at-acm</id>
    <content type="html"><![CDATA[<p><span class='caption-wrapper right'><img class='caption' src='/images/cray-1.jpg' width='' height='' alt='Cray-1 at the Swiss Federal Institute of Technology.' title='Cray-1 at the Swiss Federal Institute of Technology.'><span class='caption-text'>Cray-1 at the Swiss Federal Institute of Technology.</span></span></p>

<blockquote><p>Anyone can build a fast CPU. The trick is to build a fast system.
&nbsp;<br/>
~ Seymour Cray</p></blockquote>

<p>The Chicago chapter of the Association for Computing Machinery (<a href="http://www.chicagoacm.org/">Chicago ACM</a>) hosted a lecture titled <em>Supercomputing and You</em> yesterday evening. The talk was delivered by <a href="http://www.linkedin.com/in/sharankalwani">Sharan Kalwani</a> of <a href="http://www.fnal.gov/">Fermilab</a>. Kalwani&rsquo;s background blends mechanical engineering and computer science with decades of high performance computing experience.</p>

<h3>10x => High Performance Computing</h3>

<p>Kalwani began his talk by drawing a distinction between <em>supercomputing</em> and <em>high performance computing (HPC)</em>. Supercomputing is the buzzword that everyone knows, but the word implies that the designers are focused only on improving CPU performance. Such narrow focus could cause us to ignore important subsystems. For example, if engineers focus strictly on CPU performance, applications that are CPU-bound will quickly encounter I/O bottlenecks. High performance computing takes the entire system into account: CPU, I/O, cache, memory&hellip; anything that can influence performance.</p>

<!--more-->


<p>This article will use the terms <em>supercomputing</em> and <em>high performance computing</em> interchangably because we are discussing the field in general. In an engineering document, the distinction would be more important.</p>

<p>By definition, supercomputers perform at least ten times faster than the current state-of-the art. The definition is a moving target. The processor in today&rsquo;s smartphone would have been considered a high performance computer a decade ago.</p>

<h3>The First Supercomputer</h3>

<p><a href="http://www.cray.com/">Seymour Cray</a> is regarded as the father of the supercomputer. Cray cobbled together the first supercomputer using off-the-shelf components of the day and his unique ideas about computer architecture.</p>

<p>For example, Cray observed that the speed of an electrical signal was one bottleneck in computer performance. Electrical signals travel at the speed of light. Light can travel roughly one foot in one nanosecond.  Therefore, Cray decided that all internal cables in his new system would be less than a foot in length. No input would need to wait more than a nanosecond for a signal.</p>

<p>The 1972-era Cray supercomputer ran at a clock speed of 80MHz. It used a 64-bit word size. As a point of comparison, a 1972-era business mainframe ran at 4MHz with a 16-bit word size.</p>

<h3>Supercomputers&hellip; So What?</h3>

<p>Why do we need to spend time and money on high performance computers?  How does the general public benefit?</p>

<p>HPC enables us to solve problems that elude typical computers. For example:</p>

<ul>
<li><em>Auto safety testing</em>. Kalwani spent several years using HPC to run simulated crash tests for General Motors. A physical crash test, one in which the car is destroyed, costs $500k per car. The same test can be run in a simulator for $5k. Engineers still need to test a physical car at the end of the testing cycle, but the number of cars destroyed is drastically reduced. The business advantage of HPC-simulated tests is clear.</li>
<li><em>Nuclear testing</em>. It is very expensive (measured both in dollars and in human lives) to test a nuclear power plant. Fortunately, scientists know enough about nuclear behavior to create realistic simulations. Testing via simulation helps to manage costs and reduce accidents.</li>
<li><em>Weather forecasting</em>. The first supercomputers needed three days to predict the weather for <em>tomorrow</em>. What good is a 2-day-old weather forecast? A good forecast can save lives by telling people to evacute before a life-threatening natural disaster. Today&rsquo;s supercomputers can produce accurate weather forecasts while the reader still has time to take action.</li>
<li><em>Bioinformatics</em>. When scientists can reliably simulate drug behavior before live human testing, medical treatments can be improved and lives can be saved.</li>
<li><em>Energy exploration</em>. As long as people depend on fossil fuels, new sources need to be discovered in a timely and cost-effective way.  Supercomputers can process seismic data quickly and with sufficient granularity to tell prospectors where to drill.</li>
</ul>


<p>The bottom line: High performance computers deliver a return on investment that far outweighs their cost.</p>

<h3>Trickle Down Technology</h3>

<p>Many of the advances that we enjoy on today&rsquo;s laptops were invented by HPC architects. Kalwani shared one example: Cray invented the solid state disk (SSD) when mechanical disk drives proved to be a bottleneck. Can you imagine what an SSD must have cost in 1982 when it was invented? Today, SSDs are standard equipment on many laptops.</p>

<h3>Who Has the Fastest Supercomputer?</h3>

<p><a href="http://top500.org/">Top500.org</a> lists the fastest supercomputers on the planet, ordered by number of floating point operations per second (FLOPS). The race to be the fastest is highly competitive, so check the list for the latest champion.</p>

<p>There are those who believe that the Top 500 list is missing a few names. Some governments or companies might not want to publicize their HPC skills.</p>

<h3>Speed vs. Power</h3>

<p>Supercomputers gulp electricity. Rule of thumb: One megawatt of electricity used over the course of one year costs $1 million. The fastest supercomputer in the world uses 17 megawatts of electricity, so its owners have an annual electric bill of $17 million dollars.</p>

<p><a href="http://green500.org">The Green 500</a> list recognizes the most energy efficient supercomputers in the world.</p>

<h3>The Fourth Paradigm</h3>

<p>Kalwani closed the historical section of his talk with a discussion of <a href="http://research.microsoft.com/en-us/collaboration/fourthparadigm/">The Fourth Paradigm</a> of discovery. The concept comes from a collection of essays published by Microsoft Press. As of this writing, a free PDF of the book is available from <a href="http://research.microsoft.com/en-us/collaboration/fourthparadigm/">Microsoft Research</a>.</p>

<p>The book&rsquo;s introduction posits that there have been four paradigms of human scientific discovery:</p>

<ul>
<li><em>Empirical</em>. Started a thousand years ago. Science was all about describing natural phenomena.</li>
<li><em>Theoretical</em>. Started a few hundred years ago. Scientific understanding is achieved via models and generalizations.</li>
<li><em>Computational</em>. Started a few decades ago. Scientists seek understanding by simulating complex phenomena using computer models.</li>
<li><em>Data Exploration (eScience)</em>. Starting now. Scientists now have the technology to capture and store huge quantities of data, inexpensively and indefinitely. Software will &ldquo;look&rdquo; for trends in the data using statistical models. The software will identify trends in the data, and point them out for further investigation.</li>
</ul>


<p>One example of the Fourth Paradigm in action: Recent discoveries of sub-atomic particles were initiated by eScience. Software running on high performance computers identified trends, and the scientists followed up with deeper investigation. Discoveries followed after that.</p>

<p>Businesses have led the way in extracting trends from mountains of data. This path offered limited results for scientists because computers were too slow to handle scientific data in a timely fashion. Partial differential equations eat many CPU cycles!</p>

<p>High performance computing opens up a new universe of data insight for scientists and engineers.</p>

<h3>The Future of HPC</h3>

<p>Kalwani ended the talk by looking into his crystal ball and telling us about the future of HPC. A few trends on the horizon:</p>

<ul>
<li>Power consumption issues will dominate discussions. High performance computers are terribly inefficient. Either we need to find a free, unlimited supply of energy (unlikely) or we must design supercomputers that gulp less power.</li>
<li>GPGPUs. General purpose graphics processing units are already used for non-graphics applications, like Bitcoin mining. As more applications are discovered for the devices, faster GPGPUs will follow.</li>
<li>ARM. Advanced Risc Machine processors use less power and their performance continues to increase. Could ARM hold the key to power reduction in high performance computing?</li>
<li>Rex Parallella. Fresh from last month&rsquo;s <a href="http://sc13.supercomputing.org/">Supercomputing Conference</a>: <a href="http://www.rexcomputing.com/">Rex Computing</a> is using <a href="http://www.parallella.org/">Parallella</a> boards to build low-energy high performance computing clusters.</li>
<li>Quantum computing. Kalwani ran out of time as he was covering this item, but he shared enough to spark my interest. He explained quantum computing by using an analogy: Quantum computing is to digital computing as digital computing is to the abacus. The degree of advancement is that dramatic. <a href="http://www.dwavesys.com/">D-Wave</a> is one company exploring this area.</li>
</ul>


<h3>Conclusion</h3>

<p>Thank you Sharan Kalwani for presenting, and thank you <a href="http://www.chicagoacm.org/">Chicago ACM</a> for hosting.</p>

<h3>Acknowledgements</h3>

<p>The photo at the top of the article shows a Cray-1, the first supercomputer, on display at the <a href="http://www.epfl.ch/">Swiss Federal Institute of Technology (EPFL)</a> in Lausanne. Some of the original panels have been replaced with plexiglass.</p>
]]></content>
  </entry>
  
</feed>
